{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Reasoning In Large Language Models: CLadder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "dataset_path = \"../data/cladder/cladder-v1-q-commonsense.json\"\n",
    "with open(dataset_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "df = pd.DataFrame(data)\n",
    "df.rename(columns={'given_info': 'info'}, inplace=True)\n",
    "\n",
    "df = df[df['meta'].apply(lambda x: x.get('query_type') != 'backadj')].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]['question']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[100]['meta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 6330\n",
    "\n",
    "print('Info: ', df.iloc[index]['info'])\n",
    "print('Question: ', df.iloc[index]['question'])\n",
    "print('Answer: ', df.iloc[index]['answer'])\n",
    "print('Graph ID: ', df.iloc[index]['meta']['graph_id'])\n",
    "print('Query type: ', df.iloc[index]['meta']['query_type'])\n",
    "print('Rung: ', df.iloc[index]['meta']['rung'])\n",
    "print('Formal form: ', df.iloc[index]['meta']['formal_form'])\n",
    "print('Reasoning: ' , df.iloc[index]['reasoning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['meta'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.copy()\n",
    "meta_df = df_new['meta'].apply(pd.Series)\n",
    "meta_df\n",
    "df_new = pd.concat([df_new, meta_df], axis = 1)\n",
    "df_new = df_new.drop('meta', axis = 1)\n",
    "df_new.rename(columns={'given_info': 'given_info_meta', 'given_info': 'given_info'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['query_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "df_sampled = df_new.sample(n = 1000, random_state=25)\n",
    "print(len(df_sampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_sampled.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer\n",
      "no     504\n",
      "yes    496\n",
      "Name: count, dtype: int64\n",
      "answer\n",
      "yes    4345\n",
      "no     4345\n",
      "Name: count, dtype: int64\n",
      "----------------------------------\n",
      "query_type\n",
      "marginal              209\n",
      "ate                   174\n",
      "correlation           174\n",
      "ett                   138\n",
      "det-counterfactual     95\n",
      "nie                    92\n",
      "nde                    73\n",
      "collider_bias          23\n",
      "exp_away               22\n",
      "Name: count, dtype: int64\n",
      "query_type\n",
      "marginal              1702\n",
      "ate                   1518\n",
      "correlation           1518\n",
      "ett                   1288\n",
      "nie                    874\n",
      "det-counterfactual     870\n",
      "nde                    552\n",
      "exp_away               184\n",
      "collider_bias          184\n",
      "Name: count, dtype: int64\n",
      "----------------------------------\n",
      "answer\n",
      "no     504\n",
      "yes    496\n",
      "Name: count, dtype: int64\n",
      "answer\n",
      "yes    4345\n",
      "no     4345\n",
      "Name: count, dtype: int64\n",
      "----------------------------------\n",
      "graph_id\n",
      "mediation      197\n",
      "arrowhead      188\n",
      "confounding    106\n",
      "diamond        105\n",
      "IV             102\n",
      "chain           85\n",
      "fork            84\n",
      "collision       74\n",
      "frontdoor       32\n",
      "diamondcut      27\n",
      "Name: count, dtype: int64\n",
      "graph_id\n",
      "arrowhead      1848\n",
      "mediation      1752\n",
      "IV              920\n",
      "confounding     864\n",
      "fork            800\n",
      "diamond         738\n",
      "chain           738\n",
      "collision       552\n",
      "frontdoor       262\n",
      "diamondcut      216\n",
      "Name: count, dtype: int64\n",
      "----------------------------------\n",
      "rung\n",
      "1    405\n",
      "3    398\n",
      "2    197\n",
      "Name: count, dtype: int64\n",
      "rung\n",
      "3    3584\n",
      "1    3404\n",
      "2    1702\n",
      "Name: count, dtype: int64\n",
      "----------------------------------\n",
      "query_type\n",
      "marginal              209\n",
      "ate                   174\n",
      "correlation           174\n",
      "ett                   138\n",
      "det-counterfactual     95\n",
      "nie                    92\n",
      "nde                    73\n",
      "collider_bias          23\n",
      "exp_away               22\n",
      "Name: count, dtype: int64\n",
      "query_type\n",
      "marginal              1702\n",
      "ate                   1518\n",
      "correlation           1518\n",
      "ett                   1288\n",
      "nie                    874\n",
      "det-counterfactual     870\n",
      "nde                    552\n",
      "exp_away               184\n",
      "collider_bias          184\n",
      "Name: count, dtype: int64\n",
      "----------------------------------\n",
      "story_id\n",
      "penguin                   40\n",
      "obesity_mortality         39\n",
      "blood_pressure            38\n",
      "floor_wet                 38\n",
      "simpson_hospital          37\n",
      "encouagement_program      35\n",
      "firing_squad              35\n",
      "nature_vs_nurture         34\n",
      "smoking_frontdoor         32\n",
      "vaccine_kills             32\n",
      "smoking_gene_cancer       31\n",
      "orange_scurvy             30\n",
      "neg_mediation             30\n",
      "alarm                     29\n",
      "gender_admission_state    29\n",
      "smoking_tar_cancer        28\n",
      "gender_pay                28\n",
      "simpson_vaccine           28\n",
      "firing_employee           27\n",
      "college_salary            27\n",
      "smoke_birthWeight         27\n",
      "celebrity                 26\n",
      "candle                    25\n",
      "gender_admission          25\n",
      "price                     25\n",
      "college_wage              23\n",
      "forest_fire               21\n",
      "simpson_kidneystone       21\n",
      "cholesterol               20\n",
      "simpson_drug              20\n",
      "getting_late              20\n",
      "hospitalization           20\n",
      "getting_tanned            18\n",
      "tax_smoke_birthWeight     18\n",
      "elite_students            17\n",
      "water_cholera             16\n",
      "man_in_relationship       11\n",
      "Name: count, dtype: int64\n",
      "story_id\n",
      "gender_admission_state    308\n",
      "smoking_gene_cancer       308\n",
      "smoke_birthWeight         308\n",
      "obesity_mortality         308\n",
      "nature_vs_nurture         308\n",
      "gender_pay                308\n",
      "blood_pressure            292\n",
      "neg_mediation             292\n",
      "gender_admission          292\n",
      "encouagement_program      292\n",
      "alarm                     292\n",
      "penguin                   292\n",
      "smoking_frontdoor         262\n",
      "floor_wet                 246\n",
      "college_salary            246\n",
      "smoking_tar_cancer        246\n",
      "vaccine_kills             246\n",
      "orange_scurvy             246\n",
      "firing_squad              246\n",
      "simpson_drug              216\n",
      "simpson_vaccine           216\n",
      "firing_employee           216\n",
      "simpson_kidneystone       216\n",
      "simpson_hospital          216\n",
      "getting_late              200\n",
      "forest_fire               200\n",
      "getting_tanned            200\n",
      "candle                    200\n",
      "tax_smoke_birthWeight     184\n",
      "water_cholera             184\n",
      "price                     184\n",
      "cholesterol               184\n",
      "college_wage              184\n",
      "man_in_relationship       138\n",
      "hospitalization           138\n",
      "elite_students            138\n",
      "celebrity                 138\n",
      "Name: count, dtype: int64\n",
      "----------------------------------\n",
      "polarity\n",
      "False    502\n",
      "True     498\n",
      "Name: count, dtype: int64\n",
      "polarity\n",
      "True     4360\n",
      "False    4330\n",
      "Name: count, dtype: int64\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "column_names = ['answer', 'query_type', 'answer', 'graph_id', 'rung', 'query_type', 'story_id', 'polarity']\n",
    "\n",
    "for column_name in column_names:\n",
    "    print(df_sampled[column_name].value_counts())\n",
    "    print(df_new[column_name]. value_counts())\n",
    "    print('----------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Add columns for each model to dataframe for storing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cladder = df_sampled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import add_columns_to_dataframe, generate_results, generate_results_per_rung\n",
    "\n",
    "\n",
    "model_names = ['claude-3.5-haiku']\n",
    "df_cladder = add_columns_to_dataframe(df_cladder, model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "from constants import ANTHROPIC_API_KEY\n",
    "from model_inference import intialize_anthropic_client, run_model_on_cladder\n",
    "\n",
    "client = intialize_anthropic_client(api_key=ANTHROPIC_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model_on_cladder(df=df_cladder, \n",
    "                     output_column='claude-3.5-sonnet', \n",
    "                     model='claude-3-5-sonnet-20241022', \n",
    "                     method_name='input_output', \n",
    "                     info_column='info', \n",
    "                     question_column='question', \n",
    "                     temperature=1.0, \n",
    "                     overwrite=True, \n",
    "                     min_range=0, \n",
    "                     max_range=1000, \n",
    "                     client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Save pickle\n",
    "df_cladder.to_pickle('../data/log/cladder-anthropic-sonnet' + '-' + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + '.pkl')\n",
    "\n",
    "# Read pickle\n",
    "#unpickled_df = pd.read_pickle('./cladder.pkl')\n",
    "#df_cladder = unpickled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_results(df_cladder, 'answer', model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_results_per_rung(df_cladder, 'answer', model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run the experiments with the perturbed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Read pickle\n",
    "\n",
    "df_cladder_nonsensical = pd.read_pickle('../data/cladder/nonsensical-data.pkl')\n",
    "df_cladder_anticommonsensical = pd.read_pickle('../data/cladder/anticommonsensical-data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cladder_nonsensical = add_columns_to_dataframe(df_cladder_nonsensical, model_names)\n",
    "df_cladder_anticommonsensical = add_columns_to_dataframe(df_cladder_anticommonsensical, model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model_on_cladder(df=df_cladder_nonsensical, \n",
    "                     output_column='claude-3.5-haiku', \n",
    "                     model='claude-3-5-haiku-20241022', \n",
    "                     method_name='input_output', \n",
    "                     info_column='nonsensical_info', \n",
    "                     question_column='nonsensical_question', \n",
    "                     temperature=1.0, \n",
    "                     overwrite=True, \n",
    "                     min_range=102, \n",
    "                     max_range=1000, \n",
    "                     client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model_on_cladder(df=df_cladder_anticommonsensical, \n",
    "                     output_column='claude-3.5-sonnet', \n",
    "                     model='claude-3-5-sonnet-20241022', \n",
    "                     method_name='input_output', \n",
    "                     info_column='anticommonsensical_info', \n",
    "                     question_column='anticommonsensical_question', \n",
    "                     temperature=1.0, \n",
    "                     overwrite=True, \n",
    "                     min_range=0, \n",
    "                     max_range=1000, \n",
    "                     client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model_on_cladder(df=df_cladder_nonsensical, output_column='gpt-4o-mini', model='gpt-4o-mini', method_name='input_output', info_column='nonsensical_info', question_column='nonsensical_question', temperature=1.0, overwrite=True, min_range=0, max_range=1000)\n",
    "#run_model_on_cladder(df=df_cladder_nonsensical, output_column='gpt-4o-mini', model='gpt-4o-mini', method_name='input_output', info_column='nonsensical_info', question_column='nonsensical_question', temperature=1.0, overwrite=True, min_range=0, max_range=1000)\n",
    "\n",
    "#run_model_on_cladder(df=df_cladder_anticommonsensical, output_column='gpt-4o-mini', model='gpt-4o-mini', method_name='input_output', info_column='anticommonsensical_info', question_column='anticommonsensical_question', temperature=1.0, overwrite=True, min_range=0, max_range=1000)\n",
    "#run_model_on_cladder(df=df_cladder_anticommonsensical, output_column='gpt-4o-mini', model='gpt-4o-mini', method_name='input_output', info_column='anticommonsensical_info', question_column='anticommonsensical_question', temperature=1.0, overwrite=True, min_range=0, max_range=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_results(df_cladder_nonsensical, 'answer', model_names)\n",
    "generate_results_per_rung(df_cladder_nonsensical, 'answer', model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "df_cladder_nonsensical.to_pickle('../data/log/cladder-anthropic-sonnet-nonsensical' + '-' + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + '.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cladder_anticommonsensical.to_pickle('../data/log/cladder-anthropic-sonnet-anticommonsensical' + '-' + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + '.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
