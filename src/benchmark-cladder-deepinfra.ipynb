{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Reasoning In Large Language Models: CLadder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "dataset_path = \"../data/cladder/cladder-v1-q-commonsense.json\"\n",
    "with open(dataset_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "df = pd.DataFrame(data)\n",
    "df.rename(columns={'given_info': 'info'}, inplace=True)\n",
    "\n",
    "df = df[df['meta'].apply(lambda x: x.get('query_type') != 'backadj')].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]['question']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[100]['meta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 6330\n",
    "\n",
    "print('Info: ', df.iloc[index]['info'])\n",
    "print('Question: ', df.iloc[index]['question'])\n",
    "print('Answer: ', df.iloc[index]['answer'])\n",
    "print('Graph ID: ', df.iloc[index]['meta']['graph_id'])\n",
    "print('Query type: ', df.iloc[index]['meta']['query_type'])\n",
    "print('Rung: ', df.iloc[index]['meta']['rung'])\n",
    "print('Formal form: ', df.iloc[index]['meta']['formal_form'])\n",
    "print('Reasoning: ' , df.iloc[index]['reasoning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['meta'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.copy()\n",
    "meta_df = df_new['meta'].apply(pd.Series)\n",
    "meta_df\n",
    "df_new = pd.concat([df_new, meta_df], axis = 1)\n",
    "df_new = df_new.drop('meta', axis = 1)\n",
    "df_new.rename(columns={'given_info': 'given_info_meta', 'given_info': 'given_info'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['query_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled = df_new.sample(n = 1000, random_state=25)\n",
    "print(len(df_sampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_sampled.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['answer', 'query_type', 'answer', 'graph_id', 'rung', 'query_type', 'story_id', 'polarity']\n",
    "\n",
    "for column_name in column_names:\n",
    "    print(df_sampled[column_name].value_counts())\n",
    "    print(df_new[column_name]. value_counts())\n",
    "    print('----------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Add columns for each model to dataframe for storing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cladder = df_sampled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import add_columns_to_dataframe, generate_results, generate_results_per_rung\n",
    "\n",
    "\n",
    "model_names = ['deepseek-r1', 'deepseek-v3', 'llama-3.1-70B']\n",
    "df_cladder = add_columns_to_dataframe(df_cladder, model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from constants import DEEPINFRA_API_KEY, OPENAI_API_KEY\n",
    "from model_inference import initialize_openai_client, run_model_on_cladder\n",
    "\n",
    "client = initialize_openai_client(api_key=DEEPINFRA_API_KEY, base_url=\"https://api.deepinfra.com/v1/openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the LLM\n",
    "\n",
    "run_model_on_cladder(df=df_cladder, \n",
    "                     output_column='deepseek-v3', \n",
    "                     model='deepseek-ai/DeepSeek-V3', \n",
    "                     method_name='input_output', \n",
    "                     info_column='info', \n",
    "                     question_column='question', \n",
    "                     temperature=1.0, \n",
    "                     overwrite=True, \n",
    "                     min_range=0, \n",
    "                     max_range=1000, \n",
    "                     client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Save pickle\n",
    "df_cladder.to_pickle('../data/log/cladder-deepseek' + '-' + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + '.pkl')\n",
    "\n",
    "# Read pickle\n",
    "#unpickled_df = pd.read_pickle('./cladder.pkl')\n",
    "#df_cladder = unpickled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_results(df_cladder, 'answer', model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run the experiments with the perturbed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Read pickle\n",
    "\n",
    "df_cladder_nonsensical = pd.read_pickle('../data/cladder/nonsensical-data.pkl')\n",
    "df_cladder_anticommonsensical = pd.read_pickle('../data/cladder/anticommonsensical-data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cladder_nonsensical = add_columns_to_dataframe(df_cladder_nonsensical, model_names)\n",
    "df_cladder_anticommonsensical = add_columns_to_dataframe(df_cladder_anticommonsensical, model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model_on_cladder(df=df_cladder_nonsensical, output_column='llama-8b', model='deepseek-ai/DeepSeek-V3', method_name='input_output', info_column='nonsensical_info', question_column='nonsensical_question', temperature=1.0, overwrite=True, min_range=0, max_range=1000)\n",
    "#run_model_on_cladder(df=df_cladder_nonsensical, output_column='mistral-7b', model='mistralai/Mistral-7B-Instruct-v0.3', method_name='input_output', info_column='nonsensical_info', question_column='nonsensical_question', temperature=1.0, overwrite=True, min_range=0, max_range=1000)\n",
    "#run_model_on_cladder(df=df_cladder_nonsensical, output_column='wizardlm', model='microsoft/WizardLM-2-8x22B', method_name='input_output', info_column='nonsensical_info', question_column='nonsensical_question', temperature=1.0, overwrite=True, min_range=0, max_range=1000)\n",
    "#run_model_on_cladder(df=df_cladder_nonsensical, output_column='llama-nemotron', model='nvidia/Llama-3.1-Nemotron-70B-Instruct', method_name='input_output', info_column='nonsensical_info', question_column='nonsensical_question', temperature=1.0, overwrite=True, min_range=0, max_range=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_results(df_cladder_nonsensical, 'answer', model_names)\n",
    "generate_results_per_rung(df_cladder_nonsensical, 'answer', model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "df_cladder_nonsensical.to_pickle('../data/log/cladder-openllms-nonsensical' + '-' + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + '.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
