{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program of Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements \"Program of Thoughts\" with the CLadder dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "dataset_path = \"../data/cladder/cladder-v1-q-commonsense.json\"\n",
    "with open(dataset_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "df = pd.DataFrame(data)\n",
    "df.rename(columns={'given_info': 'info'}, inplace=True)\n",
    "\n",
    "df = df[df['meta'].apply(lambda x: x.get('query_type') != 'backadj')].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info:  The overall probability of citrus intake is 18%. For patients not consuming citrus, the probability of scurvy is 68%. For patients consuming citrus, the probability of scurvy is 49%.\n",
      "Question:  Is scurvy less likely than no scurvy overall?\n",
      "Answer:  no\n",
      "Graph ID:  chain\n",
      "Query type:  marginal\n",
      "Rung:  1\n",
      "Formal form:  P(Y)\n",
      "Reasoning:  {'step0': 'Let X = eating citrus; V2 = vitmain C; Y = scurvy.', 'step1': 'X->V2,V2->Y', 'step2': 'P(Y)', 'step3': 'P(Y | X=1)*P(X=1) + P(Y | X=0)*P(X=0)', 'step4': 'P(X=1) = 0.18\\nP(Y=1 | X=0) = 0.68\\nP(Y=1 | X=1) = 0.49', 'step5': '0.18*0.49 - 0.82*0.68 = 0.65', 'end': '0.65 > 0'}\n"
     ]
    }
   ],
   "source": [
    "index = 6700\n",
    "\n",
    "print('Info: ', df.iloc[index]['info'])\n",
    "print('Question: ', df.iloc[index]['question'])\n",
    "print('Answer: ', df.iloc[index]['answer'])\n",
    "print('Graph ID: ', df.iloc[index]['meta']['graph_id'])\n",
    "print('Query type: ', df.iloc[index]['meta']['query_type'])\n",
    "print('Rung: ', df.iloc[index]['meta']['rung'])\n",
    "print('Formal form: ', df.iloc[index]['meta']['formal_form'])\n",
    "print('Reasoning: ' , df.iloc[index]['reasoning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'story_id': 'alarm',\n",
       " 'graph_id': 'mediation',\n",
       " 'mediators': ['V2'],\n",
       " 'polarity': False,\n",
       " 'groundtruth': -0.2305349321780112,\n",
       " 'query_type': 'nie',\n",
       " 'rung': 3,\n",
       " 'formal_form': 'E[Y_{X=0, V2=1} - Y_{X=0, V2=0}]',\n",
       " 'given_info': {'p(Y | X, V2)': [[0.08430222457648505, 0.5394610521458689],\n",
       "   [0.4061509701126924, 0.8620283206949241]],\n",
       "  'p(V2 | X)': [0.7416866188819116, 0.23519324071521291]},\n",
       " 'estimand': '\\\\sum_{V2 = v} P(Y=1|X =0,V2 = v)*[P(V2 = v | X = 1) âˆ’ P(V2 = v | X = 0)]',\n",
       " 'treatment': 'X',\n",
       " 'outcome': 'Y',\n",
       " 'model_id': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['meta'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.copy()\n",
    "meta_df = df_new['meta'].apply(pd.Series)\n",
    "meta_df\n",
    "df_new = pd.concat([df_new, meta_df], axis = 1)\n",
    "df_new = df_new.drop('meta', axis = 1)\n",
    "df_new.rename(columns={'given_info': 'given_info_meta', 'given_info': 'given_info'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "df_sampled = df_new.sample(n = 1000, random_state=25)\n",
    "print(len(df_sampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer\n",
      "no     504\n",
      "yes    496\n",
      "Name: count, dtype: int64\n",
      "answer\n",
      "yes    4345\n",
      "no     4345\n",
      "Name: count, dtype: int64\n",
      "----------------------------------\n",
      "query_type\n",
      "marginal              209\n",
      "ate                   174\n",
      "correlation           174\n",
      "ett                   138\n",
      "det-counterfactual     95\n",
      "nie                    92\n",
      "nde                    73\n",
      "collider_bias          23\n",
      "exp_away               22\n",
      "Name: count, dtype: int64\n",
      "query_type\n",
      "marginal              1702\n",
      "ate                   1518\n",
      "correlation           1518\n",
      "ett                   1288\n",
      "nie                    874\n",
      "det-counterfactual     870\n",
      "nde                    552\n",
      "exp_away               184\n",
      "collider_bias          184\n",
      "Name: count, dtype: int64\n",
      "----------------------------------\n",
      "answer\n",
      "no     504\n",
      "yes    496\n",
      "Name: count, dtype: int64\n",
      "answer\n",
      "yes    4345\n",
      "no     4345\n",
      "Name: count, dtype: int64\n",
      "----------------------------------\n",
      "graph_id\n",
      "mediation      197\n",
      "arrowhead      188\n",
      "confounding    106\n",
      "diamond        105\n",
      "IV             102\n",
      "chain           85\n",
      "fork            84\n",
      "collision       74\n",
      "frontdoor       32\n",
      "diamondcut      27\n",
      "Name: count, dtype: int64\n",
      "graph_id\n",
      "arrowhead      1848\n",
      "mediation      1752\n",
      "IV              920\n",
      "confounding     864\n",
      "fork            800\n",
      "diamond         738\n",
      "chain           738\n",
      "collision       552\n",
      "frontdoor       262\n",
      "diamondcut      216\n",
      "Name: count, dtype: int64\n",
      "----------------------------------\n",
      "rung\n",
      "1    405\n",
      "3    398\n",
      "2    197\n",
      "Name: count, dtype: int64\n",
      "rung\n",
      "3    3584\n",
      "1    3404\n",
      "2    1702\n",
      "Name: count, dtype: int64\n",
      "----------------------------------\n",
      "query_type\n",
      "marginal              209\n",
      "ate                   174\n",
      "correlation           174\n",
      "ett                   138\n",
      "det-counterfactual     95\n",
      "nie                    92\n",
      "nde                    73\n",
      "collider_bias          23\n",
      "exp_away               22\n",
      "Name: count, dtype: int64\n",
      "query_type\n",
      "marginal              1702\n",
      "ate                   1518\n",
      "correlation           1518\n",
      "ett                   1288\n",
      "nie                    874\n",
      "det-counterfactual     870\n",
      "nde                    552\n",
      "exp_away               184\n",
      "collider_bias          184\n",
      "Name: count, dtype: int64\n",
      "----------------------------------\n",
      "story_id\n",
      "penguin                   40\n",
      "obesity_mortality         39\n",
      "blood_pressure            38\n",
      "floor_wet                 38\n",
      "simpson_hospital          37\n",
      "encouagement_program      35\n",
      "firing_squad              35\n",
      "nature_vs_nurture         34\n",
      "smoking_frontdoor         32\n",
      "vaccine_kills             32\n",
      "smoking_gene_cancer       31\n",
      "orange_scurvy             30\n",
      "neg_mediation             30\n",
      "alarm                     29\n",
      "gender_admission_state    29\n",
      "smoking_tar_cancer        28\n",
      "gender_pay                28\n",
      "simpson_vaccine           28\n",
      "firing_employee           27\n",
      "college_salary            27\n",
      "smoke_birthWeight         27\n",
      "celebrity                 26\n",
      "candle                    25\n",
      "gender_admission          25\n",
      "price                     25\n",
      "college_wage              23\n",
      "forest_fire               21\n",
      "simpson_kidneystone       21\n",
      "cholesterol               20\n",
      "simpson_drug              20\n",
      "getting_late              20\n",
      "hospitalization           20\n",
      "getting_tanned            18\n",
      "tax_smoke_birthWeight     18\n",
      "elite_students            17\n",
      "water_cholera             16\n",
      "man_in_relationship       11\n",
      "Name: count, dtype: int64\n",
      "story_id\n",
      "gender_admission_state    308\n",
      "smoking_gene_cancer       308\n",
      "smoke_birthWeight         308\n",
      "obesity_mortality         308\n",
      "nature_vs_nurture         308\n",
      "gender_pay                308\n",
      "blood_pressure            292\n",
      "neg_mediation             292\n",
      "gender_admission          292\n",
      "encouagement_program      292\n",
      "alarm                     292\n",
      "penguin                   292\n",
      "smoking_frontdoor         262\n",
      "floor_wet                 246\n",
      "college_salary            246\n",
      "smoking_tar_cancer        246\n",
      "vaccine_kills             246\n",
      "orange_scurvy             246\n",
      "firing_squad              246\n",
      "simpson_drug              216\n",
      "simpson_vaccine           216\n",
      "firing_employee           216\n",
      "simpson_kidneystone       216\n",
      "simpson_hospital          216\n",
      "getting_late              200\n",
      "forest_fire               200\n",
      "getting_tanned            200\n",
      "candle                    200\n",
      "tax_smoke_birthWeight     184\n",
      "water_cholera             184\n",
      "price                     184\n",
      "cholesterol               184\n",
      "college_wage              184\n",
      "man_in_relationship       138\n",
      "hospitalization           138\n",
      "elite_students            138\n",
      "celebrity                 138\n",
      "Name: count, dtype: int64\n",
      "----------------------------------\n",
      "polarity\n",
      "False    502\n",
      "True     498\n",
      "Name: count, dtype: int64\n",
      "polarity\n",
      "True     4360\n",
      "False    4330\n",
      "Name: count, dtype: int64\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "column_names = ['answer', 'query_type', 'answer', 'graph_id', 'rung', 'query_type', 'story_id', 'polarity']\n",
    "\n",
    "for column_name in column_names:\n",
    "    print(df_sampled[column_name].value_counts())\n",
    "    print(df_new[column_name]. value_counts())\n",
    "    print('----------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Add models to dataframe for storing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cladder = df_sampled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import add_columns_to_dataframe, generate_results, generate_results_per_rung\n",
    "\n",
    "\n",
    "model_names = ['gpt-4o', 'gpt-4o-mini']\n",
    "df_cladder = add_columns_to_dataframe(df_cladder, model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For individuals who are not male and applicants to a non-competitive department, the probability of admission acceptance is 63%. For individuals who are not male and applicants to a competitive department, the probability of admission acceptance is 36%. For individuals who are male and applicants to a non-competitive department, the probability of admission acceptance is 60%. For individuals who are male and applicants to a competitive department, the probability of admission acceptance is 37%. For individuals who are not male and out-of-state residents, the probability of competitive department is 67%. For individuals who are not male and in-state residents, the probability of competitive department is 28%. For individuals who are male and out-of-state residents, the probability of competitive department is 89%. For individuals who are male and in-state residents, the probability of competitive department is 57%. The overall probability of in-state residency is 99%.\n",
      "Does gender positively affect admission status through department competitiveness?\n",
      "no\n",
      "{'step0': 'Let V2 = residency status; X = gender; V3 = department competitiveness; Y = admission status.', 'step1': 'X->V3,V2->V3,X->Y,V2->Y,V3->Y', 'step2': 'E[Y_{X=0, V3=1} - Y_{X=0, V3=0}]', 'step3': '\\\\sum_{V3=v} [\\\\sum_{V2=k} P(Y=1|X=0,V3=v)*[P(V3=v|X=1,V2=k)-P(V3=v|X=0,V2=k)]*P(V2=k)]', 'step4': 'P(Y=1 | X=0, V3=0) = 0.63\\nP(Y=1 | X=0, V3=1) = 0.36\\nP(Y=1 | X=1, V3=0) = 0.60\\nP(Y=1 | X=1, V3=1) = 0.37\\nP(V3=1 | X=0, V2=0) = 0.67\\nP(V3=1 | X=0, V2=1) = 0.28\\nP(V3=1 | X=1, V2=0) = 0.89\\nP(V3=1 | X=1, V2=1) = 0.57\\nP(V2=1) = 0.99', 'step5': '0.99 * 0.36 * (0.57 - 0.89)+ 0.01 * 0.36 * (0.28 - 0.67)= -0.08', 'end': '-0.08 < 0'}\n"
     ]
    }
   ],
   "source": [
    "index = 300\n",
    "print(df_cladder.iloc[index]['info'])\n",
    "print(df_cladder.iloc[index]['question'])\n",
    "print(df_cladder.iloc[index]['answer'])\n",
    "print(df_cladder.iloc[index]['reasoning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question_id                                                           6432\n",
       "desc_id                  gender_admission_state-arrowhead-nie-model562-...\n",
       "info                     For individuals who are not male and applicant...\n",
       "question                 Does gender positively affect admission status...\n",
       "answer                                                                  no\n",
       "reasoning                {'step0': 'Let V2 = residency status; X = gend...\n",
       "story_id                                            gender_admission_state\n",
       "graph_id                                                         arrowhead\n",
       "treated                                                                NaN\n",
       "result                                                                 NaN\n",
       "polarity                                                              True\n",
       "groundtruth                                                       -0.07786\n",
       "query_type                                                             nie\n",
       "rung                                                                     3\n",
       "formal_form                               E[Y_{X=0, V3=1} - Y_{X=0, V3=0}]\n",
       "given_info               {'p(Y | X, V3)': [[0.6308051460036148, 0.36397...\n",
       "estimand                 \\sum_{V3=v} [\\sum_{V2=k} P(Y=1|X=0,V3=v)*[P(V3...\n",
       "treatment                                                                X\n",
       "outcome                                                                  Y\n",
       "model_id                                                               562\n",
       "mediators                                                             [V3]\n",
       "baseline                                                               NaN\n",
       "collider                                                               NaN\n",
       "action                                                                 NaN\n",
       "gpt-4o                                                                None\n",
       "gpt-4o_reasoning                                                      None\n",
       "gpt-4o-mini                                                           None\n",
       "gpt-4o-mini_reasoning                                                 None\n",
       "Name: 300, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cladder.iloc[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Initialize prompts and REPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/langchain_experimental/utilities/__init__.py:2: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_experimental.utilities.python import PythonREPL\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import Tool\n",
    "from langchain_experimental.utilities import PythonREPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_repl = PythonREPL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_repl.run(\"print(1+1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 8\n",
    "info = df_cladder.iloc[index]['info']\n",
    "question = df_cladder.iloc[index]['question']\n",
    "answer = df_cladder.iloc[index]['answer']\n",
    "rung = df_cladder.iloc[index]['rung']\n",
    "reasoning = df_cladder.iloc[index]['reasoning']\n",
    "\n",
    "print(info)\n",
    "print(question)\n",
    "print(answer)\n",
    "print(rung)\n",
    "print(reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt = \"\"\"Generate dowhy code ONLY to solve this problem. \n",
    "\n",
    "Question: \n",
    "For patients not assigned the drug treatment, the probability of low cholesterol is 54%. For patients assigned the drug treatment, the probability of low cholesterol is 52%. For patients not assigned the drug treatment, the probability of taking of all assigned drugs is 79%. For patients assigned the drug treatment, the probability of taking of all assigned drugs is 43%.\n",
    "\n",
    "Don't mistake p(X|Y) and p(X and Y), \n",
    "\n",
    "Code: \n",
    "import dowhy\n",
    "from dowhy import CausalModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of observations in the synthetic dataset\n",
    "n = 1000\n",
    "\n",
    "the probaility of X and Y is 0.45\n",
    "p(X | Y) = 0.54\n",
    "# Given probabilities\n",
    "p_assigned_drug = 0.5  # Assume 50% of patients are assigned the drug treatment\n",
    "p_low_cholesterol_given_no_drug = 0.54\n",
    "p_low_cholesterol_given_drug = 0.52\n",
    "p_takes_all_assigned_drugs_given_no_drug = 0.79\n",
    "p_takes_all_assigned_drugs_given_drug = 0.43\n",
    "\n",
    "# Generate whether the patient was assigned the drug treatment (0 = not assigned, 1 = assigned)\n",
    "assigned_drug = np.random.choice([0, 1], size=n, p=[1 - p_assigned_drug, p_assigned_drug])\n",
    "\n",
    "# Generate whether the patient takes all assigned drugs based on whether they were assigned the drug treatment\n",
    "takes_all_drugs = np.array([\n",
    "    np.random.binomial(1, p_takes_all_assigned_drugs_given_no_drug if drug == 0 else p_takes_all_assigned_drugs_given_drug)\n",
    "    for drug in assigned_drug\n",
    "])\n",
    "\n",
    "# Generate whether the patient has low cholesterol based on drug treatment and whether they take all assigned drugs\n",
    "low_cholesterol = np.array([\n",
    "    np.random.binomial(1, p_low_cholesterol_given_no_drug if drug == 0 else p_low_cholesterol_given_drug)\n",
    "    for drug in assigned_drug\n",
    "])\n",
    "\n",
    "# Create the DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'AssignedDrug': assigned_drug,\n",
    "    'TakesAllDrugs': takes_all_drugs,\n",
    "    'LowCholesterol': low_cholesterol\n",
    "})\n",
    "\n",
    "\n",
    "# Define the causal model\n",
    "model = CausalModel(\n",
    "    data=data,\n",
    "    treatment='TakesAllDrugs',  # Taking all drugs is the treatment\n",
    "    outcome='LowCholesterol',   # Low cholesterol is the outcome\n",
    "    graph=\"digraph {TakesAllDrugs -> LowCholesterol;}\"  # Causal graph\n",
    ")\n",
    "\n",
    "# Estimate the causal effect using a linear regression method\n",
    "causal_estimate = model.estimate_effect(\n",
    "    identified_estimand=model.identify_effect(),\n",
    "    method_name=\"backdoor.linear_regression\"\n",
    ")\n",
    "\n",
    "# Print the causal estimate for additional insights\n",
    "print(\"Causal Estimate:\", causal_estimate.value)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#prompt_question =  info + ' ' + question + custom_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt = ''' Generate dowhy code ONLY to solve this problem.  \n",
    "\n",
    "Info:  The overall probability of citrus intake is 18%. For patients not consuming citrus, the probability of scurvy is 68%. For patients consuming citrus, the probability of scurvy is 49%.\n",
    "Question:  Is scurvy less likely than no scurvy overall?\n",
    "\n",
    "Don't mistake p(X|Y) and p(X and Y),\n",
    "Code: \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dowhy\n",
    "from dowhy import CausalModel\n",
    "\n",
    "# Given probabilities:\n",
    "p_citrus = 0.84  # P(X=1)\n",
    "p_no_citrus = 0.16  # P(X=0)\n",
    "p_no_citrus_scurvy = 0.11  # P(X=0, Y=1)\n",
    "p_citrus_scurvy = 0.45  # P(X=1, Y=1)\n",
    "\n",
    "# Calculate conditional probabilities\n",
    "p_scurvy_given_citrus = p_citrus_scurvy / p_citrus\n",
    "p_scurvy_given_no_citrus = p_no_citrus_scurvy / p_no_citrus\n",
    "\n",
    "# Generate synthetic data\n",
    "n_samples = 10000\n",
    "citrus = np.random.binomial(n=1, p=p_citrus, size=n_samples)\n",
    "\n",
    "# Generate scurvy data\n",
    "scurvy = np.zeros(n_samples)\n",
    "for i in range(n_samples):\n",
    "    if citrus[i] == 1:\n",
    "        scurvy[i] = np.random.binomial(n=1, p=p_scurvy_given_citrus)\n",
    "    else:\n",
    "        scurvy[i] = np.random.binomial(n=1, p=p_scurvy_given_no_citrus)\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'citrus': citrus,\n",
    "    'scurvy': scurvy\n",
    "})\n",
    "\n",
    "# Create causal model\n",
    "causal_graph = \"\"\"\n",
    "digraph {\n",
    "    citrus -> scurvy;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "model = CausalModel(\n",
    "    data=data,\n",
    "    treatment='citrus',\n",
    "    outcome='scurvy',\n",
    "    graph=causal_graph\n",
    ")\n",
    "\n",
    "# Identify and estimate causal effect\n",
    "identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)\n",
    "estimate = model.estimate_effect(\n",
    "    identified_estimand,\n",
    "    method_name=\"backdoor.linear_regression\"\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(\"Conditional Probabilities:\")\n",
    "print(f\"P(scurvy|citrus) = {p_scurvy_given_citrus:.3f}\")\n",
    "print(f\"P(scurvy|no citrus) = {p_scurvy_given_no_citrus:.3f}\")\n",
    "print(f\"Difference = {p_scurvy_given_citrus - p_scurvy_given_no_citrus:.3f}\")\n",
    "\n",
    "print(\"\\nCausal Effect Estimate:\")\n",
    "print(estimate)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run Program of Thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from constants import OPENAI_API_KEY\n",
    "from model_inference import initialize_openai_client, run_model_on_cladder\n",
    "from utils import extract_python_code\n",
    "\n",
    "client = initialize_openai_client(api_key=OPENAI_API_KEY, base_url='https://api.openai.com/v1/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/dowhy/causal_estimators/regression_estimator.py:59: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  intercept_parameter = self.model.params[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLLOWUP PROMPT IS:  Question: \n",
      "We know that citrus intake causes sufficient vitamin C, and we know that sufficient vitamin C causes scurvy. Would the patient has scurvy if citrus intake instead of absence of citrus?\n",
      " The solution after generating doWhy code to solve this problem is: linear_regression\n",
      "{'control_value': 0, 'treatment_value': 1, 'test_significance': None, 'evaluate_effect_strength': False, 'confidence_intervals': False, 'target_units': 'ate', 'effect_modifiers': []}\n",
      "Causal Estimate: 0.09799356789708619\n",
      "\n",
      " Instruction: Based on this causal estimate, answer yes or no. Think about how the causal estimate answers the question, do not do calculations, but give an explanation. Answer: \n",
      "(LOG) Prompt Question:  We know that citrus intake causes sufficient vitamin C, and we know that sufficient vitamin C causes scurvy. Would the patient has scurvy if citrus intake instead of absence of citrus?\n",
      "(LOG) Correct answer:  yes\n",
      "(LOG) Prompt Answer:  \n",
      "!!! Code generated by LLM: !!!\n",
      "\n",
      "import dowhy\n",
      "from dowhy import CausalModel\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "# Assume total number of patients is 1000\n",
      "n = 1000\n",
      "\n",
      "# Given probabilities\n",
      "p_yes_citrus = 0.54  # Probability of having sufficient vitamin C with citrus intake\n",
      "p_no_citrus = 0.45  # Probability of having scurvy without citrus intake\n",
      "\n",
      "# Generate whether the patient has citrus intake (1 = yes, 0 = no)\n",
      "citrus_intake = np.random.choice([1, 0], size=n, p=[0.5, 0.5])  # Assume equal probability for simplicity\n",
      "\n",
      "# Simulate Scurvy based on citrus intake\n",
      "scurvy = np.array([\n",
      "    np.random.binomial(1, p_no_citrus if citrus == 0 else p_yes_citrus) \n",
      "    for citrus in citrus_intake\n",
      "])\n",
      "\n",
      "# Create the DataFrame\n",
      "data = pd.DataFrame({\n",
      "    'CitrusIntake': citrus_intake,\n",
      "    'Scurvy': scurvy\n",
      "})\n",
      "\n",
      "# Define the causal model\n",
      "model = CausalModel(\n",
      "    data=data,\n",
      "    treatment='CitrusIntake',  # Citrus intake is the treatment\n",
      "    outcome='Scurvy',          # Scurvy is the outcome\n",
      "    graph=\"digraph {CitrusIntake -> Scurvy;}\"  # Causal graph\n",
      ")\n",
      "\n",
      "# Estimate the causal effect using a linear regression method\n",
      "causal_estimate = model.estimate_effect(\n",
      "    identified_estimand=model.identify_effect(),\n",
      "    method_name=\"backdoor.linear_regression\"\n",
      ")\n",
      "\n",
      "# Print the causal estimate for additional insights\n",
      "print(\"Causal Estimate:\", causal_estimate.value)\n",
      "!!! Solution from Python interpreter: !!!\n",
      "\n",
      "linear_regression\n",
      "{'control_value': 0, 'treatment_value': 1, 'test_significance': None, 'evaluate_effect_strength': False, 'confidence_intervals': False, 'target_units': 'ate', 'effect_modifiers': []}\n",
      "Causal Estimate: 0.09799356789708619\n",
      "\n",
      "!!! Final answer: !!!\n",
      "\n",
      "Based on the causal estimate of approximately 0.098, we can interpret this finding in the context of the initial question regarding citrus intake and scurvy. The estimate indicates a small but positive causal effect of citrus intake on preventing scurvy; in other words, an increase in citrus intake is associated with a decrease in the likelihood of having scurvy. Given that sufficient citrus intake provides enough vitamin C, which is crucial for preventing scurvy, this suggests that if a patient is consuming citrus, they are less likely to develop scurvy.\n",
      "\n",
      "Therefore, if citrus intake is present, it is reasonable to conclude that the patient would not have scurvy. Based on the evidence from the causal estimate, we can confidently answer: **no**, the patient would not have scurvy if citrus intake is sufficient.\n",
      "(LOG) Extracted Answer :  no\n",
      "(LOG) Generated answer for row number:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/dowhy/causal_estimators/regression_estimator.py:59: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  intercept_parameter = self.model.params[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLLOWUP PROMPT IS:  Question: \n",
      "For nonsmokers, the probability of high tar deposit is 34%. For smokers, the probability of high tar deposit is 70%. For nonsmokers and with no tar deposit, the probability of lung cancer is 33%. For nonsmokers and with high tar deposit, the probability of lung cancer is 62%. For smokers and with no tar deposit, the probability of lung cancer is 19%. For smokers and with high tar deposit, the probability of lung cancer is 52%. The overall probability of smoking is 29%. Will smoking decrease the chance of lung cancer?\n",
      " The solution after generating doWhy code to solve this problem is: linear_regression\n",
      "{'control_value': 0, 'treatment_value': 1, 'test_significance': None, 'evaluate_effect_strength': False, 'confidence_intervals': False, 'target_units': 'ate', 'effect_modifiers': []}\n",
      "Causal Estimate: -0.008768608381992227\n",
      "\n",
      " Instruction: Based on this causal estimate, answer yes or no. Think about how the causal estimate answers the question, do not do calculations, but give an explanation. Answer: \n",
      "(LOG) Prompt Question:  For nonsmokers, the probability of high tar deposit is 34%. For smokers, the probability of high tar deposit is 70%. For nonsmokers and with no tar deposit, the probability of lung cancer is 33%. For nonsmokers and with high tar deposit, the probability of lung cancer is 62%. For smokers and with no tar deposit, the probability of lung cancer is 19%. For smokers and with high tar deposit, the probability of lung cancer is 52%. The overall probability of smoking is 29%. Will smoking decrease the chance of lung cancer?\n",
      "(LOG) Correct answer:  no\n",
      "(LOG) Prompt Answer:  \n",
      "!!! Code generated by LLM: !!!\n",
      "\n",
      "import dowhy\n",
      "from dowhy import CausalModel\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "# Set a random seed for reproducibility\n",
      "np.random.seed(42)\n",
      "\n",
      "# Number of observations in the synthetic dataset\n",
      "n = 1000\n",
      "\n",
      "# Given probabilities for smoking and lung cancer\n",
      "p_smoker = 0.29  # overall probability of being a smoker\n",
      "p_high_tar_given_smoker = 0.70\n",
      "p_high_tar_given_nonsmoker = 0.34\n",
      "p_lung_cancer_given_high_tar_smoker = 0.52\n",
      "p_lung_cancer_given_no_tar_smoker = 0.19\n",
      "p_lung_cancer_given_high_tar_nonsmoker = 0.62\n",
      "p_lung_cancer_given_no_tar_nonsmoker = 0.33\n",
      "\n",
      "# Generate whether the individual is a smoker (0 = nonsmoker, 1 = smoker)\n",
      "smoker = np.random.choice([0, 1], size=n, p=[1 - p_smoker, p_smoker])\n",
      "\n",
      "# Generate whether the individual has high tar deposit based on smoking status\n",
      "high_tar = np.array([\n",
      "    np.random.binomial(1, p_high_tar_given_smoker if s == 1 else p_high_tar_given_nonsmoker)\n",
      "    for s in smoker\n",
      "])\n",
      "\n",
      "# Generate whether the individual has lung cancer based on smoking status and tar deposit\n",
      "lung_cancer = np.array([\n",
      "    np.random.binomial(1, p_lung_cancer_given_high_tar_smoker if (s == 1 and t == 1) else\n",
      "                              p_lung_cancer_given_no_tar_smoker if (s == 1 and t == 0) else\n",
      "                              p_lung_cancer_given_high_tar_nonsmoker if (s == 0 and t == 1) else\n",
      "                              p_lung_cancer_given_no_tar_nonsmoker)\n",
      "    for s, t in zip(smoker, high_tar)\n",
      "])\n",
      "\n",
      "# Create the DataFrame\n",
      "data = pd.DataFrame({\n",
      "    'Smoker': smoker,\n",
      "    'HighTar': high_tar,\n",
      "    'LungCancer': lung_cancer\n",
      "})\n",
      "\n",
      "# Define the causal model\n",
      "model = CausalModel(\n",
      "    data=data,\n",
      "    treatment='Smoker',  # Smoking status is the treatment\n",
      "    outcome='LungCancer',   # Lung cancer is the outcome\n",
      "    graph=\"digraph {Smoker -> LungCancer; Smoker -> HighTar; HighTar -> LungCancer;}\"  # Causal graph\n",
      ")\n",
      "\n",
      "# Estimate the causal effect using a linear regression method\n",
      "causal_estimate = model.estimate_effect(\n",
      "    identified_estimand=model.identify_effect(),\n",
      "    method_name=\"backdoor.linear_regression\"\n",
      ")\n",
      "\n",
      "# Print the causal estimate for additional insights\n",
      "print(\"Causal Estimate:\", causal_estimate.value)\n",
      "!!! Solution from Python interpreter: !!!\n",
      "\n",
      "linear_regression\n",
      "{'control_value': 0, 'treatment_value': 1, 'test_significance': None, 'evaluate_effect_strength': False, 'confidence_intervals': False, 'target_units': 'ate', 'effect_modifiers': []}\n",
      "Causal Estimate: -0.008768608381992227\n",
      "\n",
      "!!! Final answer: !!!\n",
      "\n",
      "The causal estimate of -0.0088 indicates a very small negative effect of smoking on the probability of developing lung cancer. In simple terms, this suggests that smoking does not significantly increase the likelihood of lung cancer compared to nonsmokers. Given this context, the answer to the question of whether smoking decreases the chance of lung cancer is \"no.\" \n",
      "\n",
      "The negative value of the causal estimate implies that smoking may slightly lower the probability of lung cancer, contrary to common health knowledge. However, since the effect is very small and not statistically significant, it reinforces the understanding that smoking does not decrease the chance of lung cancer. Overall, considering the established connection between smoking and increased health risks, particularly lung cancer, the conclusion is that smoking does not decrease the chance of lung cancer.\n",
      "(LOG) Extracted Answer :  no\n",
      "(LOG) Generated answer for row number:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/dowhy/causal_estimators/regression_estimator.py:59: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  intercept_parameter = self.model.params[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLLOWUP PROMPT IS:  Question: \n",
      "The overall probability of taking the elevator is 31%. For those who choose to take the stairs, the probability of penguin death is 45%. For those who choose to take the elevator, the probability of penguin death is 34%. Is penguin death less likely than penguin lives overall?\n",
      " The solution after generating doWhy code to solve this problem is: linear_regression\n",
      "{'control_value': 0, 'treatment_value': 1, 'test_significance': None, 'evaluate_effect_strength': False, 'confidence_intervals': False, 'target_units': 'ate', 'effect_modifiers': []}\n",
      "Causal Estimate: 0.018510987986919747\n",
      "\n",
      " Instruction: Based on this causal estimate, answer yes or no. Think about how the causal estimate answers the question, do not do calculations, but give an explanation. Answer: \n",
      "(LOG) Prompt Question:  The overall probability of taking the elevator is 31%. For those who choose to take the stairs, the probability of penguin death is 45%. For those who choose to take the elevator, the probability of penguin death is 34%. Is penguin death less likely than penguin lives overall?\n",
      "(LOG) Correct answer:  yes\n",
      "(LOG) Prompt Answer:  \n",
      "!!! Code generated by LLM: !!!\n",
      "\n",
      "import dowhy\n",
      "from dowhy import CausalModel\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "# Set a random seed for reproducibility\n",
      "np.random.seed(42)\n",
      "\n",
      "# Number of observations in the synthetic dataset\n",
      "n = 1000\n",
      "\n",
      "# Given probabilities\n",
      "p_assigned_drug = 0.5  # Assume 50% of patients are assigned the drug treatment\n",
      "p_low_cholesterol_given_no_drug = 0.54\n",
      "p_low_cholesterol_given_drug = 0.52\n",
      "p_takes_all_assigned_drugs_given_no_drug = 0.79\n",
      "p_takes_all_assigned_drugs_given_drug = 0.43\n",
      "\n",
      "# Generate whether the patient was assigned the drug treatment (0 = not assigned, 1 = assigned)\n",
      "assigned_drug = np.random.choice([0, 1], size=n, p=[1 - p_assigned_drug, p_assigned_drug])\n",
      "\n",
      "# Generate whether the patient takes all assigned drugs based on whether they were assigned the drug treatment\n",
      "takes_all_drugs = np.array([\n",
      "    np.random.binomial(1, p_takes_all_assigned_drugs_given_no_drug if drug == 0 else p_takes_all_assigned_drugs_given_drug)\n",
      "    for drug in assigned_drug\n",
      "])\n",
      "\n",
      "# Generate whether the patient has low cholesterol based on drug treatment and whether they take all assigned drugs\n",
      "low_cholesterol = np.array([\n",
      "    np.random.binomial(1, p_low_cholesterol_given_no_drug if drug == 0 else p_low_cholesterol_given_drug)\n",
      "    for drug in assigned_drug\n",
      "])\n",
      "\n",
      "# Create the DataFrame\n",
      "data = pd.DataFrame({\n",
      "    'AssignedDrug': assigned_drug,\n",
      "    'TakesAllDrugs': takes_all_drugs,\n",
      "    'LowCholesterol': low_cholesterol\n",
      "})\n",
      "\n",
      "# Define the causal model\n",
      "model = CausalModel(\n",
      "    data=data,\n",
      "    treatment='TakesAllDrugs',  # Taking all drugs is the treatment\n",
      "    outcome='LowCholesterol',   # Low cholesterol is the outcome\n",
      "    graph=\"digraph {TakesAllDrugs -> LowCholesterol;}\"  # Causal graph\n",
      ")\n",
      "\n",
      "# Estimate the causal effect using a linear regression method\n",
      "causal_estimate = model.estimate_effect(\n",
      "    identified_estimand=model.identify_effect(),\n",
      "    method_name=\"backdoor.linear_regression\"\n",
      ")\n",
      "\n",
      "# Print the causal estimate for additional insights\n",
      "print(\"Causal Estimate:\", causal_estimate.value)\n",
      "!!! Solution from Python interpreter: !!!\n",
      "\n",
      "linear_regression\n",
      "{'control_value': 0, 'treatment_value': 1, 'test_significance': None, 'evaluate_effect_strength': False, 'confidence_intervals': False, 'target_units': 'ate', 'effect_modifiers': []}\n",
      "Causal Estimate: 0.018510987986919747\n",
      "\n",
      "!!! Final answer: !!!\n",
      "\n",
      "To determine whether penguin death is less likely than penguin lives overall, we need to analyze the causal estimate provided. The causal estimate is approximately 0.0185, which suggests that, when comparing the probabilities of penguin deaths between those who take the stairs versus those who take the elevator, there is a slight tendency towards increased penguin deaths associated with taking the elevator over the stairs.\n",
      "\n",
      "Here's the reasoning: \n",
      "\n",
      "1. The overall probability of penguin death among those who take the elevator is lower (34%) compared to those who take the stairs (45%).\n",
      "2. The causal estimate being positive (0.0185) indicates that, on average, taking the elevator is associated with a slightly higher risk of penguin death, compared to taking the stairs.\n",
      "3. However, since the probabilities indicate that a significant proportion of individuals still survive (66% for the elevator and 55% for the stairs), it implies that penguin lives are still more likely overall despite the observed risks.\n",
      "\n",
      "Given this context, the causal estimate does not contradict the idea that penguin lives are indeed more likely than penguin deaths when considering the overall situation. \n",
      "\n",
      "Therefore, the answer is: **yes**, penguin death is less likely than penguin lives overall.\n",
      "(LOG) Extracted Answer :  yes\n",
      "(LOG) Generated answer for row number:  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/dowhy/causal_estimators/regression_estimator.py:59: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  intercept_parameter = self.model.params[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLLOWUP PROMPT IS:  Question: \n",
      "For normal weight people, the probability of long lifespan is 85%. For obese people, the probability of long lifespan is 64%. Will obesity decrease the chance of long lifespan?\n",
      " The solution after generating doWhy code to solve this problem is: linear_regression\n",
      "{'control_value': 0, 'treatment_value': 1, 'test_significance': None, 'evaluate_effect_strength': False, 'confidence_intervals': False, 'target_units': 'ate', 'effect_modifiers': []}\n",
      "Causal Estimate: 0.018510987986919747\n",
      "\n",
      " Instruction: Based on this causal estimate, answer yes or no. Think about how the causal estimate answers the question, do not do calculations, but give an explanation. Answer: \n",
      "(LOG) Prompt Question:  For normal weight people, the probability of long lifespan is 85%. For obese people, the probability of long lifespan is 64%. Will obesity decrease the chance of long lifespan?\n",
      "(LOG) Correct answer:  yes\n",
      "(LOG) Prompt Answer:  \n",
      "!!! Code generated by LLM: !!!\n",
      "\n",
      "import dowhy\n",
      "from dowhy import CausalModel\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "# Set a random seed for reproducibility\n",
      "np.random.seed(42)\n",
      "\n",
      "# Number of observations in the synthetic dataset\n",
      "n = 1000\n",
      "\n",
      "# Given probabilities\n",
      "p_assigned_drug = 0.5  # Assume 50% of patients are assigned the drug treatment\n",
      "p_low_cholesterol_given_no_drug = 0.54\n",
      "p_low_cholesterol_given_drug = 0.52\n",
      "p_takes_all_assigned_drugs_given_no_drug = 0.79\n",
      "p_takes_all_assigned_drugs_given_drug = 0.43\n",
      "\n",
      "# Generate whether the patient was assigned the drug treatment (0 = not assigned, 1 = assigned)\n",
      "assigned_drug = np.random.choice([0, 1], size=n, p=[1 - p_assigned_drug, p_assigned_drug])\n",
      "\n",
      "# Generate whether the patient takes all assigned drugs based on whether they were assigned the drug treatment\n",
      "takes_all_drugs = np.array([\n",
      "    np.random.binomial(1, p_takes_all_assigned_drugs_given_no_drug if drug == 0 else p_takes_all_assigned_drugs_given_drug)\n",
      "    for drug in assigned_drug\n",
      "])\n",
      "\n",
      "# Generate whether the patient has low cholesterol based on drug treatment and whether they take all assigned drugs\n",
      "low_cholesterol = np.array([\n",
      "    np.random.binomial(1, p_low_cholesterol_given_no_drug if drug == 0 else p_low_cholesterol_given_drug)\n",
      "    for drug in assigned_drug\n",
      "])\n",
      "\n",
      "# Create the DataFrame\n",
      "data = pd.DataFrame({\n",
      "    'AssignedDrug': assigned_drug,\n",
      "    'TakesAllDrugs': takes_all_drugs,\n",
      "    'LowCholesterol': low_cholesterol\n",
      "})\n",
      "\n",
      "# Define the causal model\n",
      "model = CausalModel(\n",
      "    data=data,\n",
      "    treatment='TakesAllDrugs',  # Taking all drugs is the treatment\n",
      "    outcome='LowCholesterol',     # Low cholesterol is the outcome\n",
      "    graph=\"digraph {TakesAllDrugs -> LowCholesterol;}\"\n",
      ")\n",
      "\n",
      "# Estimate the causal effect using a linear regression method\n",
      "causal_estimate = model.estimate_effect(\n",
      "    identified_estimand=model.identify_effect(),\n",
      "    method_name=\"backdoor.linear_regression\"\n",
      ")\n",
      "\n",
      "# Print the causal estimate for additional insights\n",
      "print(\"Causal Estimate:\", causal_estimate.value)\n",
      "!!! Solution from Python interpreter: !!!\n",
      "\n",
      "linear_regression\n",
      "{'control_value': 0, 'treatment_value': 1, 'test_significance': None, 'evaluate_effect_strength': False, 'confidence_intervals': False, 'target_units': 'ate', 'effect_modifiers': []}\n",
      "Causal Estimate: 0.018510987986919747\n",
      "\n",
      "!!! Final answer: !!!\n",
      "\n",
      "Yes, obesity decreases the chance of a long lifespan. The causal estimate of approximately 0.0185 indicates a slight negative impact on the likelihood of achieving a long lifespan for obese individuals compared to those of normal weight. This suggests that being obese is associated with a decrease in the probability of having a long lifespan, which aligns with the data provided that shows lower probabilities of long lifespan for obese individuals (64%) compared to normal weight individuals (85%).\n",
      "(LOG) Extracted Answer :  yes\n",
      "(LOG) Generated answer for row number:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/dowhy/causal_estimators/regression_estimator.py:59: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  intercept_parameter = self.model.params[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLLOWUP PROMPT IS:  Question: \n",
      "For those who choose to take the stairs and penguins who are sad, the probability of penguin death is 31%. For those who choose to take the stairs and penguins who are happy, the probability of penguin death is 78%. For those who choose to take the elevator and penguins who are sad, the probability of penguin death is 48%. For those who choose to take the elevator and penguins who are happy, the probability of penguin death is 85%. For those who choose to take the stairs, the probability of penguin happiness is 74%. For those who choose to take the elevator, the probability of penguin happiness is 29%. Does my decision negatively affect penguin survival through penguin mood?\n",
      " The solution after generating doWhy code to solve this problem is: linear_regression\n",
      "{'control_value': 0, 'treatment_value': 1, 'test_significance': None, 'evaluate_effect_strength': False, 'confidence_intervals': False, 'target_units': 'ate', 'effect_modifiers': []}\n",
      "Causal Estimate: 0.1034437239740631\n",
      "\n",
      " Instruction: Based on this causal estimate, answer yes or no. Think about how the causal estimate answers the question, do not do calculations, but give an explanation. Answer: \n",
      "(LOG) Prompt Question:  For those who choose to take the stairs and penguins who are sad, the probability of penguin death is 31%. For those who choose to take the stairs and penguins who are happy, the probability of penguin death is 78%. For those who choose to take the elevator and penguins who are sad, the probability of penguin death is 48%. For those who choose to take the elevator and penguins who are happy, the probability of penguin death is 85%. For those who choose to take the stairs, the probability of penguin happiness is 74%. For those who choose to take the elevator, the probability of penguin happiness is 29%. Does my decision negatively affect penguin survival through penguin mood?\n",
      "(LOG) Correct answer:  yes\n",
      "(LOG) Prompt Answer:  \n",
      "!!! Code generated by LLM: !!!\n",
      "\n",
      "import dowhy\n",
      "from dowhy import CausalModel\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "# Set a random seed for reproducibility\n",
      "np.random.seed(42)\n",
      "\n",
      "# Number of observations in the synthetic dataset\n",
      "n = 1000\n",
      "\n",
      "# Given probabilities\n",
      "p_assigned_stairs = 0.5  # Assume 50% of participants choose stairs\n",
      "p_happy_given_stairs = 0.74\n",
      "p_happy_given_elevator = 0.29\n",
      "p_death_given_happy_stairs = 0.78\n",
      "p_death_given_sad_stairs = 0.31\n",
      "p_death_given_happy_elevator = 0.85\n",
      "p_death_given_sad_elevator = 0.48\n",
      "\n",
      "# Generate whether a participant chose stairs or elevator (0 = elevator, 1 = stairs)\n",
      "chosen_mode = np.random.choice([0, 1], size=n, p=[1 - p_assigned_stairs, p_assigned_stairs])\n",
      "\n",
      "# Generate whether the penguin is happy based on the mode chosen\n",
      "penguin_happiness = np.array([\n",
      "    np.random.binomial(1, p_happy_given_stairs if mode == 1 else p_happy_given_elevator)\n",
      "    for mode in chosen_mode\n",
      "])\n",
      "\n",
      "# Generate whether the penguin dies based on their happiness and the mode chosen\n",
      "penguin_death = np.array([\n",
      "    np.random.binomial(1, p_death_given_happy_stairs if mode == 1 and happy == 1 else\n",
      "                       p_death_given_sad_stairs if mode == 1 and happy == 0 else\n",
      "                       p_death_given_happy_elevator if mode == 0 and happy == 1 else\n",
      "                       p_death_given_sad_elevator)\n",
      "    for mode, happy in zip(chosen_mode, penguin_happiness)\n",
      "])\n",
      "\n",
      "# Create the DataFrame\n",
      "data = pd.DataFrame({\n",
      "    'ChosenMode': chosen_mode,  # 0 for elevator, 1 for stairs\n",
      "    'PenguinHappiness': penguin_happiness,\n",
      "    'PenguinDeath': penguin_death\n",
      "})\n",
      "\n",
      "# Define the causal model\n",
      "model = CausalModel(\n",
      "    data=data,\n",
      "    treatment='ChosenMode',  # Choosing stairs/elevator is the treatment\n",
      "    outcome='PenguinDeath',  # Penguin death is the outcome\n",
      "    graph=\"digraph {ChosenMode -> PenguinHappiness; ChosenMode -> PenguinDeath; PenguinHappiness -> PenguinDeath;}\"  # Causal graph\n",
      ")\n",
      "\n",
      "# Estimate the causal effect using a linear regression method\n",
      "causal_estimate = model.estimate_effect(\n",
      "    identified_estimand=model.identify_effect(),\n",
      "    method_name=\"backdoor.linear_regression\"\n",
      ")\n",
      "\n",
      "# Print the causal estimate for additional insights\n",
      "print(\"Causal Estimate:\", causal_estimate.value)\n",
      "!!! Solution from Python interpreter: !!!\n",
      "\n",
      "linear_regression\n",
      "{'control_value': 0, 'treatment_value': 1, 'test_significance': None, 'evaluate_effect_strength': False, 'confidence_intervals': False, 'target_units': 'ate', 'effect_modifiers': []}\n",
      "Causal Estimate: 0.1034437239740631\n",
      "\n",
      "!!! Final answer: !!!\n",
      "\n",
      "Yes, your decision negatively affects penguin survival through penguin mood. The causal estimate of approximately 0.103 indicates that there is a significant difference in penguin death probabilities based on the choice of stairs versus the elevator, linked to the mood of the penguins. A positive causal estimate suggests that taking the stairs, which is associated with a higher probability of penguin happiness, is likely contributing to a lower chance of penguin death relative to taking the elevator, where penguin happiness is lower. Thus, your decision to take the stairs or elevator plays a role in influencing penguin moods, which in turn affects their survival.\n",
      "(LOG) Extracted Answer :  yes\n",
      "(LOG) Generated answer for row number:  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/dowhy/causal_estimators/regression_estimator.py:59: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  intercept_parameter = self.model.params[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLLOWUP PROMPT IS:  Question: \n",
      "For those who choose to take the stairs and penguins who are sad, the probability of penguin death is 81%. For those who choose to take the stairs and penguins who are happy, the probability of penguin death is 55%. For those who choose to take the elevator and penguins who are sad, the probability of penguin death is 43%. For those who choose to take the elevator and penguins who are happy, the probability of penguin death is 23%. For those who choose to take the stairs, the probability of penguin happiness is 42%. For those who choose to take the elevator, the probability of penguin happiness is 71%. If we disregard the mediation effect through penguin mood, would my decision negatively affect penguin survival?\n",
      " The solution after generating doWhy code to solve this problem is: linear_regression\n",
      "{'control_value': 0, 'treatment_value': 1, 'test_significance': None, 'evaluate_effect_strength': False, 'confidence_intervals': False, 'target_units': 'ate', 'effect_modifiers': []}\n",
      "Causal Estimate: 0.018510987986919747\n",
      "\n",
      " Instruction: Based on this causal estimate, answer yes or no. Think about how the causal estimate answers the question, do not do calculations, but give an explanation. Answer: \n",
      "(LOG) Prompt Question:  For those who choose to take the stairs and penguins who are sad, the probability of penguin death is 81%. For those who choose to take the stairs and penguins who are happy, the probability of penguin death is 55%. For those who choose to take the elevator and penguins who are sad, the probability of penguin death is 43%. For those who choose to take the elevator and penguins who are happy, the probability of penguin death is 23%. For those who choose to take the stairs, the probability of penguin happiness is 42%. For those who choose to take the elevator, the probability of penguin happiness is 71%. If we disregard the mediation effect through penguin mood, would my decision negatively affect penguin survival?\n",
      "(LOG) Correct answer:  yes\n",
      "(LOG) Prompt Answer:  \n",
      "!!! Code generated by LLM: !!!\n",
      "\n",
      "import dowhy\n",
      "from dowhy import CausalModel\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "# Set a random seed for reproducibility\n",
      "np.random.seed(42)\n",
      "\n",
      "# Number of observations in the synthetic dataset\n",
      "n = 1000\n",
      "\n",
      "# Given probabilities\n",
      "p_assigned_drug = 0.5  # Assume 50% of patients are assigned the drug treatment\n",
      "p_low_cholesterol_given_no_drug = 0.54\n",
      "p_low_cholesterol_given_drug = 0.52\n",
      "p_takes_all_assigned_drugs_given_no_drug = 0.79\n",
      "p_takes_all_assigned_drugs_given_drug = 0.43\n",
      "\n",
      "# Generate whether the patient was assigned the drug treatment (0 = not assigned, 1 = assigned)\n",
      "assigned_drug = np.random.choice([0, 1], size=n, p=[1 - p_assigned_drug, p_assigned_drug])\n",
      "\n",
      "# Generate whether the patient takes all assigned drugs based on whether they were assigned the drug treatment\n",
      "takes_all_drugs = np.array([\n",
      "    np.random.binomial(1, p_takes_all_assigned_drugs_given_no_drug if drug == 0 else p_takes_all_assigned_drugs_given_drug)\n",
      "    for drug in assigned_drug\n",
      "])\n",
      "\n",
      "# Generate whether the patient has low cholesterol based on drug treatment and whether they take all assigned drugs\n",
      "low_cholesterol = np.array([\n",
      "    np.random.binomial(1, p_low_cholesterol_given_no_drug if drug == 0 else p_low_cholesterol_given_drug)\n",
      "    for drug in assigned_drug\n",
      "])\n",
      "\n",
      "# Create the DataFrame\n",
      "data = pd.DataFrame({\n",
      "    'AssignedDrug': assigned_drug,\n",
      "    'TakesAllDrugs': takes_all_drugs,\n",
      "    'LowCholesterol': low_cholesterol\n",
      "})\n",
      "\n",
      "# Define the causal model\n",
      "model = CausalModel(\n",
      "    data=data,\n",
      "    treatment='TakesAllDrugs',  # Taking all drugs is the treatment\n",
      "    outcome='LowCholesterol',   # Low cholesterol is the outcome\n",
      "    graph=\"digraph {TakesAllDrugs -> LowCholesterol;}\"  # Causal graph\n",
      ")\n",
      "\n",
      "# Estimate the causal effect using a linear regression method\n",
      "causal_estimate = model.estimate_effect(\n",
      "    identified_estimand=model.identify_effect(),\n",
      "    method_name=\"backdoor.linear_regression\"\n",
      ")\n",
      "\n",
      "# Print the causal estimate for additional insights\n",
      "print(\"Causal Estimate:\", causal_estimate.value)\n",
      "!!! Solution from Python interpreter: !!!\n",
      "\n",
      "linear_regression\n",
      "{'control_value': 0, 'treatment_value': 1, 'test_significance': None, 'evaluate_effect_strength': False, 'confidence_intervals': False, 'target_units': 'ate', 'effect_modifiers': []}\n",
      "Causal Estimate: 0.018510987986919747\n",
      "\n",
      "!!! Final answer: !!!\n",
      "\n",
      "Based on the causal estimate of approximately 0.0185, the answer is **no**. \n",
      "\n",
      "This estimate indicates that the effect of choosing stairs versus the elevator on penguin survival is very small, suggesting that the choice of taking the stairs does not significantly increase the probability of penguin death. In simpler terms, the decision to take the stairs has a negligible impact on the survival of penguins when considering the probabilities provided. Thus, while there may be some effect, it is not substantial enough to be seen as negatively impacting penguin survival.\n",
      "(LOG) Extracted Answer :  no\n",
      "(LOG) Generated answer for row number:  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/dowhy/causal_estimators/regression_estimator.py:59: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  intercept_parameter = self.model.params[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLLOWUP PROMPT IS:  Question: \n",
      "The overall probability of smoking mother is 29%. For infants with nonsmoking mothers, the probability of normal infant birth weight is 57%. For infants with smoking mothers, the probability of normal infant birth weight is 12%. Is normal infant birth weight more likely than low infant birth weight overall?\n",
      " The solution after generating doWhy code to solve this problem is: linear_regression\n",
      "{'control_value': 0, 'treatment_value': 1, 'test_significance': None, 'evaluate_effect_strength': False, 'confidence_intervals': False, 'target_units': 'ate', 'effect_modifiers': []}\n",
      "Causal Estimate: -0.46576256999940224\n",
      "\n",
      " Instruction: Based on this causal estimate, answer yes or no. Think about how the causal estimate answers the question, do not do calculations, but give an explanation. Answer: \n",
      "(LOG) Prompt Question:  The overall probability of smoking mother is 29%. For infants with nonsmoking mothers, the probability of normal infant birth weight is 57%. For infants with smoking mothers, the probability of normal infant birth weight is 12%. Is normal infant birth weight more likely than low infant birth weight overall?\n",
      "(LOG) Correct answer:  no\n",
      "(LOG) Prompt Answer:  \n",
      "!!! Code generated by LLM: !!!\n",
      "\n",
      "import dowhy\n",
      "from dowhy import CausalModel\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "# Set a random seed for reproducibility\n",
      "np.random.seed(42)\n",
      "\n",
      "# Number of observations in the synthetic dataset\n",
      "n = 1000\n",
      "\n",
      "# Given probabilities\n",
      "p_smoking_mother = 0.29  # Probability of smoking mother\n",
      "p_normal_weight_given_no_smoking = 0.57  # Normal weight if mother is nonsmoking\n",
      "p_normal_weight_given_smoking = 0.12  # Normal weight if mother is smoking\n",
      "\n",
      "# Generate whether the mother smokes (0 = nonsmoking, 1 = smoking)\n",
      "smoking_mother = np.random.choice([0, 1], size=n, p=[1 - p_smoking_mother, p_smoking_mother])\n",
      "\n",
      "# Generate normal birth weight based on mother's smoking status\n",
      "normal_weight = np.array([\n",
      "    np.random.binomial(1, p_normal_weight_given_no_smoking if mother == 0 else p_normal_weight_given_smoking)\n",
      "    for mother in smoking_mother\n",
      "])\n",
      "\n",
      "# Create the DataFrame\n",
      "data = pd.DataFrame({\n",
      "    'SmokingMother': smoking_mother,\n",
      "    'NormalWeight': normal_weight\n",
      "})\n",
      "\n",
      "# Define the causal model\n",
      "model = CausalModel(\n",
      "    data=data,\n",
      "    treatment='SmokingMother',  # Mother's smoking status is the treatment\n",
      "    outcome='NormalWeight',     # Normal birth weight is the outcome\n",
      "    graph=\"digraph {SmokingMother -> NormalWeight;}\"  # Causal graph\n",
      ")\n",
      "\n",
      "# Estimate the causal effect using a linear regression method\n",
      "causal_estimate = model.estimate_effect(\n",
      "    identified_estimand=model.identify_effect(),\n",
      "    method_name=\"backdoor.linear_regression\"\n",
      ")\n",
      "\n",
      "# Print the causal estimate for additional insights\n",
      "print(\"Causal Estimate:\", causal_estimate.value)\n",
      "!!! Solution from Python interpreter: !!!\n",
      "\n",
      "linear_regression\n",
      "{'control_value': 0, 'treatment_value': 1, 'test_significance': None, 'evaluate_effect_strength': False, 'confidence_intervals': False, 'target_units': 'ate', 'effect_modifiers': []}\n",
      "Causal Estimate: -0.46576256999940224\n",
      "\n",
      "!!! Final answer: !!!\n",
      "\n",
      "The causal estimate of approximately -0.47 suggests a negative effect on the likelihood of normal infant birth weight associated with smoking mothers compared to nonsmoking mothers. Since the value is negative, it indicates that smoking mothers have a significantly lower probability of having infants with normal birth weights compared to nonsmoking mothers. As such, considering the overall context and the probabilities given, it can be inferred that low infant birth weight is indeed more likely than normal infant birth weight when taking into account the prevalence of smoking mothers in the population.  \n",
      "\n",
      "Therefore, the answer is: **No**, normal infant birth weight is not more likely overall than low infant birth weight.\n",
      "(LOG) Extracted Answer :  no\n",
      "(LOG) Generated answer for row number:  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/dowhy/causal_estimators/regression_estimator.py:59: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  intercept_parameter = self.model.params[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLLOWUP PROMPT IS:  Question: \n",
      "We know that vaccination causes having smallpox and severe vaccination reaction. having smallpox or severe vaccination reaction causes smallpox survival. Would the person dies from smallpox if vaccination instead of lack of vaccination?\n",
      " The solution after generating doWhy code to solve this problem is: linear_regression\n",
      "{'control_value': 0, 'treatment_value': 1, 'test_significance': None, 'evaluate_effect_strength': False, 'confidence_intervals': False, 'target_units': 'ate', 'effect_modifiers': []}\n",
      "Causal Estimate: 0.049677788400382616\n",
      "\n",
      " Instruction: Based on this causal estimate, answer yes or no. Think about how the causal estimate answers the question, do not do calculations, but give an explanation. Answer: \n",
      "(LOG) Prompt Question:  We know that vaccination causes having smallpox and severe vaccination reaction. having smallpox or severe vaccination reaction causes smallpox survival. Would the person dies from smallpox if vaccination instead of lack of vaccination?\n",
      "(LOG) Correct answer:  no\n",
      "(LOG) Prompt Answer:  \n",
      "!!! Code generated by LLM: !!!\n",
      "\n",
      "import dowhy\n",
      "from dowhy import CausalModel\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "# Set a random seed for reproducibility\n",
      "np.random.seed(42)\n",
      "\n",
      "# Number of observations in the synthetic dataset\n",
      "n = 1000\n",
      "\n",
      "# Given probabilities\n",
      "p_vaccination = 0.5  # Assume 50% are vaccinated\n",
      "p_smallpox_given_no_vaccination = 0.70  # Probability of having smallpox without vaccination\n",
      "p_smallpox_given_vaccination = 0.05  # Probability of having smallpox with vaccination\n",
      "p_severe_reaction_given_vaccination = 0.01  # Probability of severe reaction with vaccination\n",
      "p_smallpox_survival_given_smallpox = 0.90  # Survival rate after smallpox\n",
      "\n",
      "# Generate whether the individual was vaccinated (0 = not vaccinated, 1 = vaccinated)\n",
      "vaccination = np.random.choice([0, 1], size=n, p=[1 - p_vaccination, p_vaccination])\n",
      "\n",
      "# Generate the presence of smallpox based on vaccination status\n",
      "smallpox = np.array([\n",
      "    np.random.binomial(1, p_smallpox_given_no_vaccination if vacc == 0 else p_smallpox_given_vaccination)\n",
      "    for vacc in vaccination\n",
      "])\n",
      "\n",
      "# Generate severe reaction based on vaccination\n",
      "severe_reaction = np.array([\n",
      "    np.random.binomial(1, 0) if vacc == 0 else np.random.binomial(1, p_severe_reaction_given_vaccination)\n",
      "    for vacc in vaccination\n",
      "])\n",
      "\n",
      "# Determine whether the person survives based on if they got smallpox\n",
      "survival = np.array([\n",
      "    np.random.binomial(1, p_smallpox_survival_given_smallpox) if sickness == 1 else 1\n",
      "    for sickness in smallpox\n",
      "])\n",
      "\n",
      "# Create the DataFrame\n",
      "data = pd.DataFrame({\n",
      "    'Vaccination': vaccination,\n",
      "    'Smallpox': smallpox,\n",
      "    'SevereReaction': severe_reaction,\n",
      "    'Survival': survival\n",
      "})\n",
      "\n",
      "# Define the causal model\n",
      "model = CausalModel(\n",
      "    data=data,\n",
      "    treatment='Vaccination',  # Vaccination is the treatment\n",
      "    outcome='Survival',       # Survival is the outcome\n",
      "    graph=\"digraph {Vaccination -> Smallpox; Vaccination -> SevereReaction; Smallpox -> Survival; SevereReaction -> Survival;}\"  # Causal graph\n",
      ")\n",
      "\n",
      "# Estimate the causal effect using a linear regression method\n",
      "causal_estimate = model.estimate_effect(\n",
      "    identified_estimand=model.identify_effect(),\n",
      "    method_name=\"backdoor.linear_regression\"\n",
      ")\n",
      "\n",
      "# Print the causal estimate for additional insights\n",
      "print(\"Causal Estimate:\", causal_estimate.value)\n",
      "!!! Solution from Python interpreter: !!!\n",
      "\n",
      "linear_regression\n",
      "{'control_value': 0, 'treatment_value': 1, 'test_significance': None, 'evaluate_effect_strength': False, 'confidence_intervals': False, 'target_units': 'ate', 'effect_modifiers': []}\n",
      "Causal Estimate: 0.049677788400382616\n",
      "\n",
      "!!! Final answer: !!!\n",
      "\n",
      "The causal estimate of approximately 0.0497 suggests a small positive effect of vaccination on the outcome being measured, which appears to be related to smallpox survival. Given that this estimate is greater than zero, it indicates that there is a likelihood that vaccination could result in a small increase in the chances of survival from smallpox compared to not being vaccinated.\n",
      "\n",
      "However, since this effect size is quite small (close to 0), it does not imply a significant impact on the probability of death from smallpox due to vaccination. Therefore, the answer to the question of whether a person would die from smallpox if vaccinatedâ€”given the analysis represented by the causal estimateâ€”is likely \"no.\" The vaccination seems to provide at least some slight improvement in survival against smallpox, rather than resulting in death.\n",
      "(LOG) Extracted Answer :  no\n",
      "(LOG) Generated answer for row number:  16\n",
      "FOLLOWUP PROMPT IS:  Question: \n",
      "The overall probability of obesity is 20%. For normal weight people, the probability of long lifespan is 70%. For obese people, the probability of long lifespan is 37%. Is long lifespan more likely than short lifespan overall?\n",
      " The solution after generating doWhy code to solve this problem is: ValueError('shapes (1000,3) and (2,) not aligned: 3 (dim 1) != 2 (dim 0)')\n",
      " Instruction: Based on this causal estimate, answer yes or no. Think about how the causal estimate answers the question, do not do calculations, but give an explanation. Answer: \n",
      "(LOG) Prompt Question:  The overall probability of obesity is 20%. For normal weight people, the probability of long lifespan is 70%. For obese people, the probability of long lifespan is 37%. Is long lifespan more likely than short lifespan overall?\n",
      "(LOG) Correct answer:  yes\n",
      "(LOG) Prompt Answer:  \n",
      "!!! Code generated by LLM: !!!\n",
      "\n",
      "import dowhy\n",
      "from dowhy import CausalModel\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "# Set a random seed for reproducibility\n",
      "np.random.seed(42)\n",
      "\n",
      "# Number of observations in the synthetic dataset\n",
      "n = 1000\n",
      "\n",
      "# Given probabilities\n",
      "p_obesity = 0.20  # Probability of obesity\n",
      "p_long_lifespan_given_normal = 0.70  # Probability of long lifespan given normal weight\n",
      "p_long_lifespan_given_obese = 0.37   # Probability of long lifespan given obese\n",
      "\n",
      "# Probabilities of lifespan based on weight status\n",
      "weight_status = np.random.choice(['normal', 'obese'], size=n, p=[1 - p_obesity, p_obesity])\n",
      "long_lifespan = np.array([\n",
      "    np.random.binomial(1, p_long_lifespan_given_normal if status == 'normal' else p_long_lifespan_given_obese)\n",
      "    for status in weight_status\n",
      "])\n",
      "\n",
      "# Create the DataFrame\n",
      "data = pd.DataFrame({\n",
      "    'WeightStatus': weight_status,\n",
      "    'LongLifespan': long_lifespan\n",
      "})\n",
      "\n",
      "# Define the causal model\n",
      "model = CausalModel(\n",
      "    data=data,\n",
      "    treatment='WeightStatus',  # Weight status is the treatment\n",
      "    outcome='LongLifespan',   # Long lifespan is the outcome\n",
      "    graph=\"digraph {WeightStatus -> LongLifespan;}\"  # Causal graph\n",
      ")\n",
      "\n",
      "# Estimate the causal effect using a linear regression method\n",
      "causal_estimate = model.estimate_effect(\n",
      "    identified_estimand=model.identify_effect(),\n",
      "    method_name=\"backdoor.linear_regression\"\n",
      ")\n",
      "\n",
      "# Print the causal estimate for additional insights\n",
      "print(\"Causal Estimate:\", causal_estimate.value)\n",
      "!!! Solution from Python interpreter: !!!\n",
      "\n",
      "ValueError('shapes (1000,3) and (2,) not aligned: 3 (dim 1) != 2 (dim 0)')\n",
      "!!! Final answer: !!!\n",
      "\n",
      "To determine if a long lifespan is more likely than a short lifespan overall, we need to consider the overall probabilities of long lifespan given the two weight categories (normal and obese) and their respective prevalence in the population.\n",
      "\n",
      "1. **Overall Obesity Probability**: 20% of the population is obese, meaning 80% are of normal weight.\n",
      "2. **Long Lifespan Probabilities**: \n",
      "   - For normal weight individuals: 70% have a long lifespan.\n",
      "   - For obese individuals: 37% have a long lifespan.\n",
      "\n",
      "To assess if long lifespan is more likely than short lifespan overall, we can find the weighted average probability of long lifespan in the entire population.\n",
      "\n",
      "- **Contribution of normal weight individuals to long lifespan**:\n",
      "  - 80% of the population is normal weight, and 70% of them have a long lifespan, contributing to a significant portion of long-lived individuals.\n",
      "\n",
      "- **Contribution of obese individuals to long lifespan**:\n",
      "  - 20% of the population is obese, and 37% of them have a long lifespan, which contributes less to the total number of long lifespans than the normal-weight individuals.\n",
      "\n",
      "If we consider these weighted contributions, normal weight individuals have a higher probability of living long lives compared to obese individuals. Given this difference and the larger proportion of normal weight individuals, it is highly likely that the cumulative probability of long lifespan in the population is more than 50%. Thus, in that case, long lifespan would indeed be more likely than short lifespan overall.\n",
      "\n",
      "Since the task specifies to answer whether long lifespan is more likely than short lifespan based on the causal estimate without performing calculations, I conclude that the answer is **Yes**. Long lifespan is more likely than short lifespan overall.\n",
      "(LOG) Extracted Answer :  yes\n",
      "(LOG) Generated answer for row number:  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/dowhy/causal_estimators/regression_estimator.py:59: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  intercept_parameter = self.model.params[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLLOWUP PROMPT IS:  Question: \n",
      "The overall probability of receives treatment is 56%. For patients not receiving treatment, the probability of recovery is 18%. For patients receiving treatment, the probability of recovery is 64%. Is recovery less likely than non-recovery overall?\n",
      " The solution after generating doWhy code to solve this problem is: linear_regression\n",
      "{'control_value': 0, 'treatment_value': 1, 'test_significance': None, 'evaluate_effect_strength': False, 'confidence_intervals': False, 'target_units': 'ate', 'effect_modifiers': []}\n",
      "Causal Estimate: 0.44083987023532845\n",
      "\n",
      " Instruction: Based on this causal estimate, answer yes or no. Think about how the causal estimate answers the question, do not do calculations, but give an explanation. Answer: \n",
      "(LOG) Prompt Question:  The overall probability of receives treatment is 56%. For patients not receiving treatment, the probability of recovery is 18%. For patients receiving treatment, the probability of recovery is 64%. Is recovery less likely than non-recovery overall?\n",
      "(LOG) Correct answer:  yes\n",
      "(LOG) Prompt Answer:  \n",
      "!!! Code generated by LLM: !!!\n",
      "\n",
      "import dowhy\n",
      "from dowhy import CausalModel\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "# Set a random seed for reproducibility\n",
      "np.random.seed(42)\n",
      "\n",
      "# Number of observations in the synthetic dataset\n",
      "n = 1000\n",
      "\n",
      "# Given probabilities\n",
      "p_assigned_drug = 0.5  # Assume 50% of patients are assigned the drug treatment\n",
      "p_recovery_given_no_drug = 0.18\n",
      "p_recovery_given_drug = 0.64\n",
      "\n",
      "# Generate whether the patient was assigned the drug treatment (0 = not assigned, 1 = assigned)\n",
      "assigned_drug = np.random.choice([0, 1], size=n, p=[1 - p_assigned_drug, p_assigned_drug])\n",
      "\n",
      "# Generate whether the patient recovers based on whether they were assigned the drug treatment\n",
      "recovery = np.array([\n",
      "    np.random.binomial(1, p_recovery_given_no_drug if drug == 0 else p_recovery_given_drug)\n",
      "    for drug in assigned_drug\n",
      "])\n",
      "\n",
      "# Create the DataFrame\n",
      "data = pd.DataFrame({\n",
      "    'AssignedDrug': assigned_drug,\n",
      "    'Recovery': recovery\n",
      "})\n",
      "\n",
      "# Define the causal model\n",
      "model = CausalModel(\n",
      "    data=data,\n",
      "    treatment='AssignedDrug',  # Drug assignment is the treatment\n",
      "    outcome='Recovery',   # Recovery is the outcome\n",
      "    graph=\"digraph {AssignedDrug -> Recovery;}\"  # Causal graph\n",
      ")\n",
      "\n",
      "# Estimate the causal effect using a linear regression method\n",
      "causal_estimate = model.estimate_effect(\n",
      "    identified_estimand=model.identify_effect(),\n",
      "    method_name=\"backdoor.linear_regression\"\n",
      ")\n",
      "\n",
      "# Print the causal estimate for additional insights\n",
      "print(\"Causal Estimate:\", causal_estimate.value)\n",
      "!!! Solution from Python interpreter: !!!\n",
      "\n",
      "linear_regression\n",
      "{'control_value': 0, 'treatment_value': 1, 'test_significance': None, 'evaluate_effect_strength': False, 'confidence_intervals': False, 'target_units': 'ate', 'effect_modifiers': []}\n",
      "Causal Estimate: 0.44083987023532845\n",
      "\n",
      "!!! Final answer: !!!\n",
      "\n",
      "Based on the causal estimate of approximately 0.44, we can interpret this as the average treatment effect (ATE) indicating that receiving treatment increases the probability of recovery by about 44 percentage points compared to not receiving treatment. \n",
      "\n",
      "Since the probability of recovery for patients not receiving treatment is 18% and for those receiving treatment is 64%, the data clearly shows that recovery is significantly more likely among those receiving treatment. \n",
      "\n",
      "Therefore, overall recovery is **not** less likely than non-recovery. Instead, it suggests that treatment greatly enhances the likelihood of recovery. \n",
      "\n",
      "Answer: No.\n",
      "(LOG) Extracted Answer :  no\n",
      "(LOG) Generated answer for row number:  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/dowhy/causal_estimators/regression_estimator.py:59: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  intercept_parameter = self.model.params[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLLOWUP PROMPT IS:  Question: \n",
      "The overall probability of college degree or higher is 80%. The probability of high school degree or lower and high salary is 14%. The probability of college degree or higher and high salary is 28%. Is the chance of high salary smaller when observing college degree or higher?\n",
      " The solution after generating doWhy code to solve this problem is: linear_regression\n",
      "{'control_value': 0, 'treatment_value': 1, 'test_significance': None, 'evaluate_effect_strength': False, 'confidence_intervals': False, 'target_units': 'ate', 'effect_modifiers': []}\n",
      "Causal Estimate: 0.14050179211469538\n",
      "Probability of high salary given college degree: 0.28\n",
      "Probability of high salary given no college degree: 0.14\n",
      "\n",
      " Instruction: Based on this causal estimate, answer yes or no. Think about how the causal estimate answers the question, do not do calculations, but give an explanation. Answer: \n",
      "(LOG) Prompt Question:  The overall probability of college degree or higher is 80%. The probability of high school degree or lower and high salary is 14%. The probability of college degree or higher and high salary is 28%. Is the chance of high salary smaller when observing college degree or higher?\n",
      "(LOG) Correct answer:  yes\n",
      "(LOG) Prompt Answer:  \n",
      "!!! Code generated by LLM: !!!\n",
      "\n",
      "import dowhy\n",
      "from dowhy import CausalModel\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "# Set a random seed for reproducibility\n",
      "np.random.seed(42)\n",
      "\n",
      "# Number of observations in the synthetic dataset\n",
      "n = 1000\n",
      "\n",
      "# Given probabilities for the college degree and high salary scenario\n",
      "p_college_or_higher = 0.80\n",
      "p_high_salary_given_low_education = 0.14\n",
      "p_high_salary_given_college = 0.28\n",
      "\n",
      "# Generate whether a person has a college degree (0 = no, 1 = yes)\n",
      "college_degree = np.random.choice([0, 1], size=n, p=[1 - p_college_or_higher, p_college_or_higher])\n",
      "\n",
      "# Generate whether a person has a high salary based on their education\n",
      "high_salary = np.array([\n",
      "    np.random.binomial(1, p_high_salary_given_low_education if degree == 0 else p_high_salary_given_college)\n",
      "    for degree in college_degree\n",
      "])\n",
      "\n",
      "# Create the DataFrame\n",
      "data = pd.DataFrame({\n",
      "    'CollegeDegree': college_degree,\n",
      "    'HighSalary': high_salary\n",
      "})\n",
      "\n",
      "# Define the causal model\n",
      "model = CausalModel(\n",
      "    data=data,\n",
      "    treatment='CollegeDegree',  # Having a college degree is the treatment\n",
      "    outcome='HighSalary',       # High salary is the outcome\n",
      "    graph=\"digraph {CollegeDegree -> HighSalary;}\"  # Causal graph\n",
      ")\n",
      "\n",
      "# Estimate the causal effect using a linear regression method\n",
      "causal_estimate = model.estimate_effect(\n",
      "    identified_estimand=model.identify_effect(),\n",
      "    method_name=\"backdoor.linear_regression\"\n",
      ")\n",
      "\n",
      "# Print the causal estimate for additional insights\n",
      "print(\"Causal Estimate:\", causal_estimate.value)\n",
      "\n",
      "# To assess if the chance of high salary is smaller with a college degree\n",
      "print(\"Probability of high salary given college degree:\", p_high_salary_given_college)\n",
      "print(\"Probability of high salary given no college degree:\", p_high_salary_given_low_education)\n",
      "!!! Solution from Python interpreter: !!!\n",
      "\n",
      "linear_regression\n",
      "{'control_value': 0, 'treatment_value': 1, 'test_significance': None, 'evaluate_effect_strength': False, 'confidence_intervals': False, 'target_units': 'ate', 'effect_modifiers': []}\n",
      "Causal Estimate: 0.14050179211469538\n",
      "Probability of high salary given college degree: 0.28\n",
      "Probability of high salary given no college degree: 0.14\n",
      "\n",
      "!!! Final answer: !!!\n",
      "\n",
      "No. \n",
      "\n",
      "The causal estimate of approximately 0.1405 indicates the effect of having a college degree on the probability of receiving a high salary. When you consider the probabilities provided, 28% of individuals with a college degree earn a high salary compared to 14% of those with a high school degree or lower. This suggests that individuals with a college degree have a higher likelihood of obtaining a high salary relative to those without, rather than a smaller chance. Therefore, the presence of a college degree is associated with an increased probability of a high salary, not a smaller chance.\n",
      "(LOG) Extracted Answer :  no\n",
      "(LOG) Generated answer for row number:  19\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_model_on_cladder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_cladder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                     \u001b[49m\u001b[43moutput_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgpt-4o-mini\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgpt-4o-mini\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprogram_of_thoughts\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                     \u001b[49m\u001b[43minfo_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minfo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mquestion_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                     \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmin_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmax_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/causal-reasoning/thesis/src/model_inference.py:142\u001b[0m, in \u001b[0;36mrun_model_on_cladder\u001b[0;34m(df, model, method_name, info_column, question_column, output_column, min_range, max_range, temperature, overwrite, self_consistency_reasoning_chains, client)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_experimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PythonREPL\n\u001b[1;32m    140\u001b[0m python_repl \u001b[38;5;241m=\u001b[39m PythonREPL()  \n\u001b[0;32m--> 142\u001b[0m generated_code \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_question\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprogram_of_thoughts_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m extracted_code \u001b[38;5;241m=\u001b[39m python_repl\u001b[38;5;241m.\u001b[39msanitize_input(extract_python_code(generated_code))    \n\u001b[1;32m    144\u001b[0m solution \u001b[38;5;241m=\u001b[39m python_repl\u001b[38;5;241m.\u001b[39mrun(extracted_code)\n",
      "File \u001b[0;32m~/causal-reasoning/thesis/src/model_inference.py:38\u001b[0m, in \u001b[0;36mgenerate_completion\u001b[0;34m(prompt, model, temperature, client)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClient not initialized.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(client) \u001b[38;5;241m==\u001b[39m openai\u001b[38;5;241m.\u001b[39mOpenAI:\n\u001b[0;32m---> 38\u001b[0m     completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(client) \u001b[38;5;241m==\u001b[39m anthropic\u001b[38;5;241m.\u001b[39mAnthropic:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/openai/_utils/_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/openai/resources/chat/completions.py:815\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    813\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    814\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 815\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/openai/_base_client.py:1277\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1265\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1272\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1274\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1275\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1276\u001b[0m     )\n\u001b[0;32m-> 1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/openai/_base_client.py:954\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    952\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 954\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/openai/_base_client.py:990\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    987\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 990\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    996\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/httpx/_client.py:915\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    907\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m    911\u001b[0m )\n\u001b[1;32m    913\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 915\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    922\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/httpx/_client.py:943\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    940\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 943\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/httpx/_client.py:980\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    978\u001b[0m     hook(request)\n\u001b[0;32m--> 980\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/httpx/_client.py:1016\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1012\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1013\u001b[0m     )\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1016\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1020\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/httpx/_transports/default.py:231\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    218\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    219\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    220\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    229\u001b[0m )\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 231\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    236\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    237\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    238\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    239\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    240\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:268\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_closed(status)\n\u001b[0;32m--> 268\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:251\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;66;03m# The ConnectionNotAvailable exception is a special case, that\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;66;03m# indicates we need to retry the request on a new connection.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;66;03m# might end up as an HTTP/2 connection, but which actually ends\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# up as HTTP/1.1.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool_lock:\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;66;03m# Maintain our position in the request queue, but reset the\u001b[39;00m\n\u001b[1;32m    262\u001b[0m         \u001b[38;5;66;03m# status so that the request becomes queued again.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectionNotAvailable()\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/httpcore/_sync/http11.py:133\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/httpcore/_sync/http11.py:111\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    105\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    106\u001b[0m     (\n\u001b[1;32m    107\u001b[0m         http_version,\n\u001b[1;32m    108\u001b[0m         status,\n\u001b[1;32m    109\u001b[0m         reason_phrase,\n\u001b[1;32m    110\u001b[0m         headers,\n\u001b[0;32m--> 111\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    113\u001b[0m         http_version,\n\u001b[1;32m    114\u001b[0m         status,\n\u001b[1;32m    115\u001b[0m         reason_phrase,\n\u001b[1;32m    116\u001b[0m         headers,\n\u001b[1;32m    117\u001b[0m     )\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    120\u001b[0m     status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m    121\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m     },\n\u001b[1;32m    128\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/httpcore/_sync/http11.py:176\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    173\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/httpcore/_sync/http11.py:212\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 212\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/ssl.py:1234\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1231\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1232\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1233\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/thesis/lib/python3.12/ssl.py:1107\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1106\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1107\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_model_on_cladder(df=df_cladder, \n",
    "                     output_column='gpt-4o-mini', \n",
    "                     model='gpt-4o-mini', \n",
    "                     method_name='program_of_thoughts', \n",
    "                     info_column='info', \n",
    "                     question_column='question', \n",
    "                     temperature=1.0, \n",
    "                     overwrite=True, \n",
    "                     min_range=19, \n",
    "                     max_range=1000, \n",
    "                     client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_openai(df, model_col_name, model, method_name, min_range, max_range, temperature=1.0, overwrite=False):\n",
    "    \n",
    "#     if model_col_name not in df.columns:\n",
    "#         raise KeyError(model_col_name + \" : Column name doesn't exist!\")\n",
    "    \n",
    "#     for i in range(min_range, max_range):\n",
    "\n",
    "#         if df.iloc[i][model_col_name] is None or overwrite == True:\n",
    "\n",
    "#             prompt_question = df.iloc[i]['info'] + \" \" + df.iloc[i]['question'] + custom_prompt\n",
    "#             generated_code = extract_python_code(input_output(prompt_question, model, temperature))\n",
    "#             generated_code = python_repl.sanitize_input(generated_code)\n",
    "#             solution = python_repl.run(generated_code)\n",
    "            \n",
    "#             followup_prompt = df.iloc[i]['info'] + \" \" + df.iloc[i]['question']  + \"The solution to this answer after generating doWhy code is: \" +  solution + \"Based on the causal estimate, answer the question with yes or no in the end.\"\n",
    "#             final_answer = input_output(followup_prompt, 'gpt-4o', 1)\n",
    "\n",
    "#             extracted_answer = extract_yes_or_no(final_answer)\n",
    "            \n",
    "#             print('Info: ', df.iloc[i]['info'])\n",
    "#             print('Question: ', df.iloc[i]['question'])\n",
    "#             print('Actual answer: ', df.iloc[i]['answer'])\n",
    "\n",
    "#             print('Generated code: ', generated_code)\n",
    "#             print('Solution: ', solution)\n",
    "#             print('PROMPT ANSWER: ', final_answer)\n",
    "#             print('EXTRACTED ANSWER: ', extracted_answer)\n",
    "            \n",
    "#             df.at[i, model_col_name] = extracted_answer\n",
    "#             df.at[i, model_col_name + '_reasoning'] = solution\n",
    "#             print('SOLUTION: ', solution)\n",
    "#             print('EXTRACTED ANSWER: ', extracted_answer)\n",
    "#             print('Generation completed: ', i)\n",
    "\n",
    "#         else:\n",
    "        \n",
    "#             print('Skipping: ', i)    \n",
    "\n",
    "# run_openai(df_cladder, model_col_name='gpt-4o', model='gpt-4o', method_name='input_output', overwrite=True, min_range=0, max_range=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
